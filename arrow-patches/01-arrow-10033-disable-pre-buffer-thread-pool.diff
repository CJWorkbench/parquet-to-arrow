diff --git a/cpp/src/parquet/arrow/reader.cc b/cpp/src/parquet/arrow/reader.cc
index 1d02f09bc..e314750ed 100644
--- a/cpp/src/parquet/arrow/reader.cc
+++ b/cpp/src/parquet/arrow/reader.cc
@@ -753,14 +753,6 @@ Status FileReaderImpl::GetRecordBatchReader(const std::vector<int>& row_groups,
                                             std::unique_ptr<RecordBatchReader>* out) {
   RETURN_NOT_OK(BoundsCheck(row_groups, column_indices));
 
-  if (reader_properties_.pre_buffer()) {
-    // PARQUET-1698/PARQUET-1820: pre-buffer row groups/column chunks if enabled
-    BEGIN_PARQUET_CATCH_EXCEPTIONS
-    reader_->PreBuffer(row_groups, column_indices, reader_properties_.async_context(),
-                       reader_properties_.cache_options());
-    END_PARQUET_CATCH_EXCEPTIONS
-  }
-
   std::vector<std::shared_ptr<ColumnReaderImpl>> readers;
   std::shared_ptr<::arrow::Schema> batch_schema;
   RETURN_NOT_OK(GetFieldReaders(column_indices, row_groups, &readers, &batch_schema));
@@ -838,15 +830,6 @@ Status FileReaderImpl::ReadRowGroups(const std::vector<int>& row_groups,
                                      std::shared_ptr<Table>* out) {
   RETURN_NOT_OK(BoundsCheck(row_groups, column_indices));
 
-  // PARQUET-1698/PARQUET-1820: pre-buffer row groups/column chunks if enabled
-  if (reader_properties_.pre_buffer()) {
-    BEGIN_PARQUET_CATCH_EXCEPTIONS
-    parquet_reader()->PreBuffer(row_groups, column_indices,
-                                reader_properties_.async_context(),
-                                reader_properties_.cache_options());
-    END_PARQUET_CATCH_EXCEPTIONS
-  }
-
   std::vector<std::shared_ptr<ColumnReaderImpl>> readers;
   std::shared_ptr<::arrow::Schema> result_schema;
   RETURN_NOT_OK(GetFieldReaders(column_indices, row_groups, &readers, &result_schema));
diff --git a/cpp/src/parquet/properties.h b/cpp/src/parquet/properties.h
index 2d9725c2b..4c4a7c04d 100644
--- a/cpp/src/parquet/properties.h
+++ b/cpp/src/parquet/properties.h
@@ -574,9 +574,7 @@ class PARQUET_EXPORT ArrowReaderProperties {
   explicit ArrowReaderProperties(bool use_threads = kArrowDefaultUseThreads)
       : use_threads_(use_threads),
         read_dict_indices_(),
-        batch_size_(kArrowDefaultBatchSize),
-        pre_buffer_(false),
-        cache_options_(::arrow::io::CacheOptions::Defaults()) {}
+        batch_size_(kArrowDefaultBatchSize) {}
 
   void set_use_threads(bool use_threads) { use_threads_ = use_threads; }
 
@@ -601,33 +599,10 @@ class PARQUET_EXPORT ArrowReaderProperties {
 
   int64_t batch_size() const { return batch_size_; }
 
-  /// Enable read coalescing.
-  ///
-  /// When enabled, the Arrow reader will pre-buffer necessary regions
-  /// of the file in-memory. This is intended to improve performance on
-  /// high-latency filesystems (e.g. Amazon S3).
-  void set_pre_buffer(bool pre_buffer) { pre_buffer_ = pre_buffer; }
-
-  bool pre_buffer() const { return pre_buffer_; }
-
-  /// Set options for read coalescing. This can be used to tune the
-  /// implementation for characteristics of different filesystems.
-  void set_cache_options(::arrow::io::CacheOptions options) { cache_options_ = options; }
-
-  ::arrow::io::CacheOptions cache_options() const { return cache_options_; }
-
-  /// Set execution context for read coalescing.
-  void set_async_context(::arrow::io::AsyncContext ctx) { async_context_ = ctx; }
-
-  ::arrow::io::AsyncContext async_context() const { return async_context_; }
-
  private:
   bool use_threads_;
   std::unordered_set<int> read_dict_indices_;
   int64_t batch_size_;
-  bool pre_buffer_;
-  ::arrow::io::AsyncContext async_context_;
-  ::arrow::io::CacheOptions cache_options_;
 };
 
 /// EXPERIMENTAL: Constructs the default ArrowReaderProperties
